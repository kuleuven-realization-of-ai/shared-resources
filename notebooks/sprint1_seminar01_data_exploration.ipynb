{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b380221-d7de-4e8d-90fc-77ede686ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload ensures that your python-files stay up-to-date: https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Move back to the root directory\n",
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "714ab511-cf58-43e0-b364-5aeca76567af",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook shows an example of data exploration.\n",
    "\n",
    "Data exploration is at the beginning of any Machine Learning project, and helps you familiarise with the problem at hand. You can generate insights like:\n",
    "* How does a traditional data sample look like?\n",
    "* How does the biggest bulk of our dataset look like? --> Helps to tackle the \"low hanging fruits\"\n",
    "* Are their outliers in our dataset and how do they look like? --> important for \"sensitive applications\" where outliers are as important as an average sample\n",
    "* What are the data's properties (i.e. dimensions, type of data, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a26e07-ada1-46b1-be48-227151b348aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from random import randint, choice\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d341befe-367b-4392-be51-3dc79ba504d4",
   "metadata": {},
   "source": [
    "## Quick data analysis - FastDup\n",
    "\n",
    "Luckily, there exist some good libraries out there that do much of the heavy lifting for you and allow you to very quickly get insights in your dataset in a few lines of code. One of these is [FastDup](https://github.com/visual-layer/fastdup). Full documentation [here](https://visual-layer.github.io/fastdup/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b764936",
   "metadata": {},
   "source": [
    "Fastdup is not included in pyproject.toml, because its dependencies are too restrictive, not allowing poetry to solve the version constraints.\n",
    "As a workaround:\n",
    "\n",
    "    1. Pip install in the notebook\n",
    "    2. This changes/breaks the environment: restart the kernel\n",
    "    3. After using the notebook, run `poetry sync` to restore the versions of all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45864fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install fastdup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20f4dc-888b-4ab0-9382-8398640f1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastdup\n",
    "\n",
    "from shutil import rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a537e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove if already exists\n",
    "if Path(\"fastdup/run\").is_dir():\n",
    "    rmtree(\"fastdup/run\")\n",
    "\n",
    "fd = fastdup.create(work_dir=\"fastdup/run\", input_dir=\"data/data/minifigures\")\n",
    "fd.run(nearest_neighbors_k=5, ccthreshold=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visual gallery of duplicates\n",
    "fd.vis.duplicates_gallery(num_images=15)\n",
    "\n",
    "# Create visual gallery of anomalies\n",
    "fd.vis.outliers_gallery(num_images=15)\n",
    "\n",
    "# Create visual gallery of clusters\n",
    "fd.vis.component_gallery(num_images=15)\n",
    "\n",
    "# Create visual gallery of blur\n",
    "fd.vis.stats_gallery(metric=\"blur\", num_images=15)\n",
    "\n",
    "# Create visual gallery of similar images\n",
    "fd.vis.similarity_gallery(num_images=15)\n",
    "\n",
    "\n",
    "# View the galleries by opening the generated HTML files in the browser (in fastdup/run/galleries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81b6c722",
   "metadata": {},
   "source": [
    "## Manual exploration\n",
    "\n",
    "In a second iteration, we'll go manually over the data to generate some deeper insights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81b6c722",
   "metadata": {},
   "source": [
    "### 1. Visualise the data\n",
    "\n",
    "Visualise a random subset of images from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92caaadc-4f73-43ad-bda5-3199b5c3cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the data paths using pathlib\n",
    "files = sorted((Path.cwd() / 'data/data/minifigures').glob('*.png'))\n",
    "n_files = len(files)\n",
    "n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c17910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the samples with a faulty name\n",
    "files = [path for path in files if path.name[0] != \".\"]\n",
    "n_files = len(files)\n",
    "n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612c13f-1eab-49bc-a1b6-555d20bcc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise 100 images at random\n",
    "_,axs=plt.subplots(10,10,figsize=(10,10))\n",
    "for i in range(10*10):\n",
    "    axs[i%10,i//10].imshow(Image.open(files[randint(0, n_files-1)]))\n",
    "_ = [ax.set_axis_off() for ax in axs.ravel()]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8f8b6f0-b36e-4123-8169-0ee86dbbaf02",
   "metadata": {},
   "source": [
    "### 2. Dataset distribution\n",
    "\n",
    "Next, when looking into the images' names, we notice that some of them have a prefix, indicating from which dataset they are. Let's extract this prefix and see what type of minifigures we can expect the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e9505-3461-4a06-adf0-09b4c2d4cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most samples, there's a dataset prefix\n",
    "files[200:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd2fdc-ebdf-4532-946c-98dbb1223a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to extract the prefix from a path\n",
    "def extract_prefix(path:Path) -> str|None:\n",
    "    \"\"\"Extract the prefix from the Path.\"\"\"\n",
    "    name = path.with_suffix('').name\n",
    "    prefix = re.search('^[a-z]+', name)\n",
    "    if prefix:\n",
    "        return prefix.group(0)\n",
    "    return None\n",
    "    \n",
    "extract_prefix(files[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445fad7-de0e-4af5-ad8b-2cdea9f2b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all the prefixes\n",
    "prefixes = [extract_prefix(p) for p in tqdm(files)]\n",
    "\n",
    "# Show to top N prefixes\n",
    "counts = Counter(prefixes)\n",
    "if None in counts: del counts[None]\n",
    "\n",
    "top_n = 10\n",
    "prefixes_ = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "prefixes_[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91040a-b2ad-4c47-a8f0-038874bac37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise dataset distribution\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(top_n), [v for _,v in prefixes_[:top_n]], zorder=2)\n",
    "plt.xticks(range(top_n), [k for k,_ in prefixes_[:top_n]])\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52899dfa-ad32-4e87-b1f5-82636a81422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples for each top_n classes\n",
    "top_n, n_col = 5, 5\n",
    "\n",
    "_,axs = plt.subplots(top_n, n_col, figsize=(n_col,top_n))\n",
    "for i in range(top_n):\n",
    "    p, n = prefixes_[i]\n",
    "    selection = [path for path,prefix in zip(files,prefixes) if prefix==p]\n",
    "    for j in range(n_col):\n",
    "        axs[i,j].imshow(Image.open(selection[randint(0,len(selection)-1)]))\n",
    "        if j == (n_col//2): axs[i,j].set_title(p)\n",
    "_ = [ax.set_axis_off() for ax in axs.ravel()]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c8f0bd6-b287-48a9-a75e-001caf3252de",
   "metadata": {},
   "source": [
    "### 3. Sizes\n",
    "\n",
    "Images have different sizes, let's investigate what the size distribution is of our dataset. This is interesting to keep in mind for later, when we start building a Machine Learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image's shapes\n",
    "shapes = [Image.open(path).size for path in tqdm(files)]\n",
    "x,y = zip(*shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebad2e-f205-4fde-99a2-cb3b15baa5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the shapes\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x, y, alpha=0.2, zorder=2)\n",
    "plt.xlabel('width'); plt.ylabel('height')\n",
    "plt.ylim(0,550); plt.xlim(0,550)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fed815-277a-414c-a99b-456f5e8cd25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who's the tall one?\n",
    "idx = [v>500 for v in x]\n",
    "Image.open(files[idx.index(True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b57c4-3292-4331-8023-6e6a3fdfac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who's the wide one?\n",
    "idx = [v>420 for v in y]\n",
    "Image.open(files[idx.index(True)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a51eea8c-6143-4de6-9453-ffd93586411f",
   "metadata": {},
   "source": [
    "### 4. Labels\n",
    "\n",
    "Next to the images themselves, we also have a `dataset.json` that contains the target labels of a few samples in our dataset. Let's have a look how this looks like!\n",
    "\n",
    "This will show us that we're working with a rather imbalanced dataset, but that there are also already several samples for each individual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5bd7d-8c09-4037-a146-83fccecabdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the dataset, show how many labels there are, and which unique labels exist\n",
    "with open('data/data/dataset.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "labels = sorted({x for y in dataset.values() for x in y})\n",
    "len(dataset), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08bb40-bb5d-4b65-8b84-6ab9af4b53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the label ratios\n",
    "counts = Counter()\n",
    "for v in dataset.values():\n",
    "    counts.update(v)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(labels, [counts[l]/len(dataset) for l in labels], zorder=2)\n",
    "plt.xticks(labels, rotation=45)\n",
    "plt.yticks([i/10 for i in range(11)], [f\"{10*i:3d}%\" for i in range(11)])\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd70bd8aa070c8218c850ba4d0e6c35f6a394929d9fdf53c70bdd6152f030d25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

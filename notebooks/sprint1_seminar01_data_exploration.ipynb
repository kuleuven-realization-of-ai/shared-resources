{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b380221-d7de-4e8d-90fc-77ede686ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload ensures that your python-files stay up-to-date: https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Move back to the root directory\n",
    "%cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "714ab511-cf58-43e0-b364-5aeca76567af",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook shows an example of data exploration.\n",
    "\n",
    "Data exploration is at the beginning of any Machine Learning project, and helps you familiarise with the problem at hand. You can generate insights like:\n",
    "* How does a traditional data sample look like?\n",
    "* How does the biggest bulk of our dataset look like? --> Helps to tackle the \"low hanging fruits\"\n",
    "* Are there outliers in our dataset and how do they look like? --> important for \"sensitive applications\" where outliers are as important as an average sample\n",
    "* What are the data's properties (i.e. dimensions, type of data, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382c23b",
   "metadata": {},
   "source": [
    "run \"uv sync --all-groups\" in the terminal to install all dependencies of all groups (dev, train) defined in pyproject.toml\n",
    "DONT FORGET TO RESTART THE KERNEL OF THE NOTEBOOK AFTER! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a26e07-ada1-46b1-be48-227151b348aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from random import choice, randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d341befe-367b-4392-be51-3dc79ba504d4",
   "metadata": {},
   "source": [
    "## Quick data analysis - FastDup\n",
    "\n",
    "Luckily, there exist some good libraries out there that do much of the heavy lifting for you and allow you to very quickly get insights in your dataset in a few lines of code. One of these is [FastDup](https://github.com/visual-layer/fastdup). Full documentation [here](https://visual-layer.github.io/fastdup/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20f4dc-888b-4ab0-9382-8398640f1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "import fastdup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a537e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove if already exists\n",
    "if Path(\"fastdup/run\").is_dir():\n",
    "    rmtree(\"fastdup/run\")\n",
    "\n",
    "fd = fastdup.create(work_dir=\"fastdup/run\", input_dir=\"data/data/minifigures\")\n",
    "fd.run(nearest_neighbors_k=5, ccthreshold=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visual gallery of duplicates\n",
    "fd.vis.duplicates_gallery(num_images=15)\n",
    "\n",
    "# Create visual gallery of anomalies\n",
    "fd.vis.outliers_gallery(num_images=15)\n",
    "\n",
    "# Create visual gallery of clusters\n",
    "fd.vis.component_gallery(num_images=15)\n",
    "\n",
    "# Create visual gallery of blur\n",
    "fd.vis.stats_gallery(metric=\"blur\", num_images=15)\n",
    "\n",
    "# Create visual gallery of similar images\n",
    "fd.vis.similarity_gallery(num_images=15)\n",
    "\n",
    "\n",
    "# View the galleries by opening the generated HTML files in the browser (in fastdup/run/galleries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81b6c722",
   "metadata": {},
   "source": [
    "## Manual exploration\n",
    "\n",
    "In a second iteration, we'll go manually over the data to generate some deeper insights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81b6c722",
   "metadata": {},
   "source": [
    "### 1. Visualise the data\n",
    "\n",
    "Visualise a random subset of images from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92caaadc-4f73-43ad-bda5-3199b5c3cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the data paths using pathlib\n",
    "files = sorted((Path.cwd() / \"data/data/minifigures\").glob(\"*.png\"))\n",
    "n_files = len(files)\n",
    "n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c17910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the samples with a faulty name\n",
    "files = [path for path in files if path.name[0] != \".\"]\n",
    "n_files = len(files)\n",
    "n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612c13f-1eab-49bc-a1b6-555d20bcc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise 100 images at random\n",
    "_, axs = plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i in range(10 * 10):\n",
    "    axs[i % 10, i // 10].imshow(Image.open(files[randint(0, n_files - 1)]))\n",
    "_ = [ax.set_axis_off() for ax in axs.ravel()]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8f8b6f0-b36e-4123-8169-0ee86dbbaf02",
   "metadata": {},
   "source": [
    "### 2. Dataset distribution\n",
    "\n",
    "Next, when looking into the images' names, we notice that some of them have a prefix, indicating from which dataset they are. Let's extract this prefix and see what type of minifigures we can expect the most. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e9505-3461-4a06-adf0-09b4c2d4cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most samples, there's a dataset prefix\n",
    "files[200:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd2fdc-ebdf-4532-946c-98dbb1223a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to extract the prefix from a path\n",
    "def extract_prefix(path: Path) -> str | None:\n",
    "    \"\"\"Extract the prefix from the Path.\"\"\"\n",
    "    name = path.with_suffix(\"\").name\n",
    "    prefix = re.search(\"^[a-z]+\", name)\n",
    "    if prefix:\n",
    "        return prefix.group(0)\n",
    "    return None\n",
    "\n",
    "\n",
    "extract_prefix(files[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445fad7-de0e-4af5-ad8b-2cdea9f2b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all the prefixes\n",
    "prefixes = [extract_prefix(p) for p in tqdm(files)]\n",
    "\n",
    "# Show to top N prefixes\n",
    "counts = Counter(prefixes)\n",
    "if None in counts:\n",
    "    del counts[None]\n",
    "\n",
    "top_n = 10\n",
    "prefixes_ = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "prefixes_[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91040a-b2ad-4c47-a8f0-038874bac37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise dataset distribution\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(top_n), [v for _, v in prefixes_[:top_n]], zorder=2)\n",
    "plt.xticks(range(top_n), [k for k, _ in prefixes_[:top_n]])\n",
    "plt.tight_layout()\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52899dfa-ad32-4e87-b1f5-82636a81422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples for each top_n classes\n",
    "top_n, n_col = 5, 5\n",
    "\n",
    "_, axs = plt.subplots(top_n, n_col, figsize=(n_col, top_n))\n",
    "for i in range(top_n):\n",
    "    p, n = prefixes_[i]\n",
    "    selection = [path for path, prefix in zip(files, prefixes) if prefix == p]\n",
    "    for j in range(n_col):\n",
    "        axs[i, j].imshow(Image.open(selection[randint(0, len(selection) - 1)]))\n",
    "        if j == (n_col // 2):\n",
    "            axs[i, j].set_title(p)\n",
    "_ = [ax.set_axis_off() for ax in axs.ravel()]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c8f0bd6-b287-48a9-a75e-001caf3252de",
   "metadata": {},
   "source": [
    "### 3. Sizes\n",
    "\n",
    "Images have different sizes, let's investigate what the size distribution is of our dataset. This is interesting to keep in mind for later, when we start building a Machine Learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image's shapes\n",
    "shapes = [Image.open(path).size for path in tqdm(files)]\n",
    "x, y = zip(*shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebad2e-f205-4fde-99a2-cb3b15baa5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the shapes\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y, alpha=0.2, zorder=2)\n",
    "plt.xlabel(\"width\")\n",
    "plt.ylabel(\"height\")\n",
    "plt.ylim(0, 550)\n",
    "plt.xlim(0, 550)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fed815-277a-414c-a99b-456f5e8cd25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who's the wide one?\n",
    "idx = [v > 500 for v in x]\n",
    "Image.open(files[idx.index(True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967b57c4-3292-4331-8023-6e6a3fdfac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who's the tall one?\n",
    "idx = [v > 420 for v in y]\n",
    "Image.open(files[idx.index(True)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a51eea8c-6143-4de6-9453-ffd93586411f",
   "metadata": {},
   "source": [
    "### 4. Labels\n",
    "\n",
    "Next to the images themselves, we also have a `dataset.json` that contains the target labels of a few samples in our dataset. Let's have a look how this looks like!\n",
    "\n",
    "This will show us that we're working with a rather imbalanced dataset, but that there are also already several samples for each individual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5bd7d-8c09-4037-a146-83fccecabdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the dataset, show how many labels there are, and which unique labels exist\n",
    "with open(\"data/data/dataset.json\") as f:\n",
    "    dataset = json.load(f)\n",
    "labels = sorted({x for y in dataset.values() for x in y})\n",
    "len(dataset), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08bb40-bb5d-4b65-8b84-6ab9af4b53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the label ratios\n",
    "counts = Counter()\n",
    "for v in dataset.values():\n",
    "    counts.update(v)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(labels, [counts[l] / len(dataset) for l in labels], zorder=2)\n",
    "plt.xticks(labels, rotation=45)\n",
    "plt.yticks([i / 10 for i in range(11)], [f\"{10 * i:3d}%\" for i in range(11)])\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minifigures-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
